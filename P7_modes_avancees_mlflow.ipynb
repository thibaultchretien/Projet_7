{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3cfc7d-627a-4d84-b295-a3eddb84925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "import nltk\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Importation de Scikit-learn pour les modèles et métriques\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (accuracy_score, recall_score, f1_score, roc_auc_score, \n",
    "                             confusion_matrix, roc_curve)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Importation des modules de traitement de texte NLTK\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# Importation de TensorFlow et Keras pour le Deep Learning\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils, layers, metrics as kmetrics\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Dense, Dropout, Embedding, LSTM, Bidirectional, \n",
    "                                     TimeDistributed, Flatten, GlobalAveragePooling1D)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Importation de Gensim pour le traitement des modèles Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Importation de XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Définition du chemin des données\n",
    "path_data = '/Users/chretien/OpenClassroom/Openclassroom7/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b13c2-4e98-4be6-8289-43243dc3c582",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Import et traitement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97434d25-c4c1-460c-a4f5-76a0a1440363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target          id                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", sep=',', encoding='ISO-8859-1', header=None,names=['target', 'id', 'date', 'flag', 'user', 'text'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d00c08a0-3d96-44ad-848d-9269bbc863e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>774733</th>\n",
       "      <td>0</td>\n",
       "      <td>me want to watch transformers too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455075</th>\n",
       "      <td>0</td>\n",
       "      <td>Wow he said he's retiring! Sad!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527542</th>\n",
       "      <td>0</td>\n",
       "      <td>My car is broken - overheating. (Engine smokin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60790</th>\n",
       "      <td>0</td>\n",
       "      <td>end of the festivities.. fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273179</th>\n",
       "      <td>0</td>\n",
       "      <td>Chris and I are now 520 points behind @binnsy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1362765</th>\n",
       "      <td>1</td>\n",
       "      <td>I enjoy your replies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392443</th>\n",
       "      <td>1</td>\n",
       "      <td>Fun thing for today: Finding saved emails from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213913</th>\n",
       "      <td>1</td>\n",
       "      <td>@susanam90210 Thanks for liking my Mariachi pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337828</th>\n",
       "      <td>1</td>\n",
       "      <td>has had a bitch of a day. But hey, I'm still s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237526</th>\n",
       "      <td>1</td>\n",
       "      <td>going to the pool soon...jetting out early</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target                                               text\n",
       "0 774733        0                 me want to watch transformers too \n",
       "  455075        0                   Wow he said he's retiring! Sad! \n",
       "  527542        0  My car is broken - overheating. (Engine smokin...\n",
       "  60790         0                     end of the festivities.. fuck \n",
       "  273179        0  Chris and I are now 520 points behind @binnsy ...\n",
       "...           ...                                                ...\n",
       "1 1362765       1                              I enjoy your replies \n",
       "  1392443       1  Fun thing for today: Finding saved emails from...\n",
       "  1213913       1  @susanam90210 Thanks for liking my Mariachi pi...\n",
       "  1337828       1  has had a bitch of a day. But hey, I'm still s...\n",
       "  1237526       1        going to the pool soon...jetting out early \n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Garder uniquement colonnes target et text \n",
    "df = df[['target', 'text']]\n",
    "\n",
    "# Remplacer target 4 par 1\n",
    "df[\"target\"] = df[\"target\"].replace(4, 1)\n",
    "\n",
    "# Sample\n",
    "df_sample = df.groupby('target', as_index=False).apply(lambda x : x.sample(frac=0.001))\n",
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7354289d-736b-41b5-8e19-9d8815bc476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "def tokenizer_fct(sentence) :\n",
    "    word_tokens = word_tokenize(sentence)\n",
    "    # print(word_tokens)\n",
    "    return word_tokens\n",
    "\n",
    "\n",
    "# Tokenizer split\n",
    "\n",
    "def tokenizer_split_fct(sentence) :\n",
    "    word_tokens = sentence.split(' ')\n",
    "    # print(word_tokens)\n",
    "    return word_tokens\n",
    "\n",
    "# Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_w = list(set(stopwords.words('english')))\n",
    "\n",
    "def stop_word_filter_fct(list_words) :\n",
    "    filtered_w = [w for w in list_words if not w in stop_w]\n",
    "    # print(filtered_w)    \n",
    "    return filtered_w\n",
    "\n",
    "# lower case et alpha (not \"@\")\n",
    "def lower_alpha_fct(list_words) :\n",
    "    fw = [w.lower() for w in list_words if w.isalpha()]\n",
    "    # print(fw)\n",
    "    return fw\n",
    "\n",
    "# lower case et alpha (not \"@\")\n",
    "def lower_not_user_fct(list_words) :\n",
    "    fw = [w.lower() for w in list_words if not w.startswith(\"@\")]\n",
    "    # print(fw\n",
    "    return fw\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------Lemmatizer-----------------------------------\n",
    "\n",
    "\n",
    "def lemma_fct(list_words) :\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_w = [lemmatizer.lemmatize(w) for w in list_words]\n",
    "    return lem_w\n",
    "    \n",
    "#------------------------------Stemming-----------------------------------\n",
    "\n",
    "\n",
    "def stemma_fct(list_words) :\n",
    "    stemming = PorterStemmer()\n",
    "    stemma_w = [stemming.stem(w) for w in list_words]\n",
    "    return stemma_w\n",
    "\n",
    "\n",
    "#-------------------# Fonction de préparation des tweets----------------------------\n",
    "\n",
    "\n",
    "# Fonction de préparation des questions\n",
    "def transform_text(text) :\n",
    "    word_tokens = tokenizer_split_fct(text)\n",
    "    f_w = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_not_user_fct(f_w)\n",
    "    #lem_w = lemma_fct(lw)\n",
    "    filtered_w = stop_word_filter_fct(lw)\n",
    "    # print(filtered_w)\n",
    "    trans_sentence = ' '.join(filtered_w)\n",
    "    \n",
    "    return trans_sentence\n",
    "\n",
    "\n",
    "# Fonction de préparation des questions\n",
    "def transform_text_lem(text) :\n",
    "    word_tokens = tokenizer_split_fct(text)\n",
    "    f_w = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_not_user_fct(f_w)\n",
    "    lem_w = lemma_fct(lw)\n",
    "    filtered_w = stop_word_filter_fct(lem_w)\n",
    "    # print(filtered_w)\n",
    "    trans_sentence = ' '.join(filtered_w)\n",
    "    \n",
    "    return trans_sentence\n",
    "\n",
    "\n",
    "# Fonction de préparation des questions\n",
    "def transform_text_stemma(text) :\n",
    "    word_tokens = tokenizer_split_fct(text)\n",
    "    f_w = stop_word_filter_fct(word_tokens)\n",
    "    lw = lower_not_user_fct(f_w)\n",
    "    stemma_w = stemma_fct(lw)\n",
    "    filtered_w = stop_word_filter_fct(stemma_w)\n",
    "    # print(filtered_w)\n",
    "    trans_sentence = ' '.join(filtered_w)\n",
    "    \n",
    "    return trans_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe7586e-689f-4a3e-934a-89b29dd2da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text_base</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>text_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>774733</th>\n",
       "      <td>0</td>\n",
       "      <td>want watch transformers</td>\n",
       "      <td>want watch transformer</td>\n",
       "      <td>want watch transform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455075</th>\n",
       "      <td>0</td>\n",
       "      <td>wow said he's retiring! sad!</td>\n",
       "      <td>wow said he's retiring! sad!</td>\n",
       "      <td>wow said he' retiring! sad!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527542</th>\n",
       "      <td>0</td>\n",
       "      <td>car broken - overheating. (engine smoking = ba...</td>\n",
       "      <td>car broken - overheating. (engine smoking = ba...</td>\n",
       "      <td>car broken - overheating. (engin smoke = bad) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60790</th>\n",
       "      <td>0</td>\n",
       "      <td>end festivities.. fuck</td>\n",
       "      <td>end festivities.. fuck</td>\n",
       "      <td>end festivities.. fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273179</th>\n",
       "      <td>0</td>\n",
       "      <td>chris 520 points behind sair.</td>\n",
       "      <td>chris 520 point behind sair.</td>\n",
       "      <td>chri 520 point behind sair.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1362765</th>\n",
       "      <td>1</td>\n",
       "      <td>enjoy replies</td>\n",
       "      <td>enjoy reply</td>\n",
       "      <td>enjoy repli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392443</th>\n",
       "      <td>1</td>\n",
       "      <td>fun thing today: finding saved emails friends ...</td>\n",
       "      <td>fun thing today: finding saved email friend ye...</td>\n",
       "      <td>fun thing today: find save email friend year a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213913</th>\n",
       "      <td>1</td>\n",
       "      <td>thanks liking mariachi pic. i'll try find anot...</td>\n",
       "      <td>thanks liking mariachi pic. i'll try find anot...</td>\n",
       "      <td>thank like mariachi pic. i'll tri find anoth r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337828</th>\n",
       "      <td>1</td>\n",
       "      <td>bitch day. hey, i'm still smiling</td>\n",
       "      <td>bitch day. hey, i'm still smiling</td>\n",
       "      <td>bitch day. hey, i'm still smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237526</th>\n",
       "      <td>1</td>\n",
       "      <td>going pool soon...jetting early</td>\n",
       "      <td>going pool soon...jetting early</td>\n",
       "      <td>go pool soon...jet earli</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           target                                          text_base  \\\n",
       "0 774733        0                           want watch transformers    \n",
       "  455075        0                      wow said he's retiring! sad!    \n",
       "  527542        0  car broken - overheating. (engine smoking = ba...   \n",
       "  60790         0                            end festivities.. fuck    \n",
       "  273179        0                     chris 520 points behind sair.    \n",
       "...           ...                                                ...   \n",
       "1 1362765       1                                     enjoy replies    \n",
       "  1392443       1  fun thing today: finding saved emails friends ...   \n",
       "  1213913       1  thanks liking mariachi pic. i'll try find anot...   \n",
       "  1337828       1                 bitch day. hey, i'm still smiling    \n",
       "  1237526       1                   going pool soon...jetting early    \n",
       "\n",
       "                                                  text_lemma  \\\n",
       "0 774733                             want watch transformer    \n",
       "  455075                       wow said he's retiring! sad!    \n",
       "  527542   car broken - overheating. (engine smoking = ba...   \n",
       "  60790                              end festivities.. fuck    \n",
       "  273179                       chris 520 point behind sair.    \n",
       "...                                                      ...   \n",
       "1 1362765                                       enjoy reply    \n",
       "  1392443  fun thing today: finding saved email friend ye...   \n",
       "  1213913  thanks liking mariachi pic. i'll try find anot...   \n",
       "  1337828                 bitch day. hey, i'm still smiling    \n",
       "  1237526                   going pool soon...jetting early    \n",
       "\n",
       "                                                   text_stem  \n",
       "0 774733                               want watch transform   \n",
       "  455075                        wow said he' retiring! sad!   \n",
       "  527542   car broken - overheating. (engin smoke = bad) ...  \n",
       "  60790                              end festivities.. fuck   \n",
       "  273179                        chri 520 point behind sair.   \n",
       "...                                                      ...  \n",
       "1 1362765                                       enjoy repli   \n",
       "  1392443  fun thing today: find save email friend year a...  \n",
       "  1213913  thank like mariachi pic. i'll tri find anoth r...  \n",
       "  1337828                   bitch day. hey, i'm still smile   \n",
       "  1237526                          go pool soon...jet earli   \n",
       "\n",
       "[1600 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# afficher DataFrame clean \n",
    "\n",
    "tweets = pd.DataFrame()\n",
    "tweets['target'] = df_sample['target']\n",
    "tweets['text_base'] = df_sample['text'].apply(lambda x : transform_text(x))\n",
    "tweets['text_lemma'] = df_sample['text'].apply(lambda x : transform_text_lem(x))\n",
    "tweets['text_stem'] = df_sample['text'].apply(lambda x : transform_text_stemma(x))\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce89285-1d80-45f8-9f38-76536a47fcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train test \n",
    "train0, df_test = train_test_split(tweets, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Split Train Val \n",
    "df_train, df_val = train_test_split(train0, test_size=0.25, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e346156-8481-4e2d-bde1-d250f49f9416",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target']\n",
    "y_val = df_val['target']\n",
    "y_test = df_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8752dc-c92a-448f-9fc7-3755201712fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# W2V - Fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ea18db-d2d1-49b4-9538-743867cca7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_size=200 # Chaque mot sera représenté par un vecteur de taille 200\n",
    "w2v_window=5 # le modèle regarde les 5 mots précédents et les 5 mots suivants\n",
    "w2v_min_count=1 # tous les mots présents au moins une fois dans le corpus seront pris en compte dans l'apprentissage.\n",
    "w2v_epochs=100 # Le modèle s'entraîne sur 100 itérations du corpus.\n",
    "maxlen=200\n",
    "\n",
    " # Définition des paramètres en dur\n",
    "max_sequence_len = 36  # Longueur maximale des séquences après padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c379a5-4ce1-4220-8732-dd207eaffe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforme notre target(0 ou 1) en un vecteur de 2 dimensions\n",
    "# Uniquement pour W2V\n",
    "\n",
    "def label_encode_fct(y_train, y_val, y_test) :\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    #print(y_train)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    #print(num_classes)\n",
    "    y_train = utils.to_categorical(y_train, num_classes)\n",
    "    y_val = utils.to_categorical(y_val, num_classes)\n",
    "    y_test = utils.to_categorical(y_test, num_classes)\n",
    "    #print(y_train)\n",
    "\n",
    "    return y_train, y_val, y_test\n",
    "\n",
    "y_train, y_val, y_test = label_encode_fct(y_train,y_val, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e6ded00-9a12-4cd7-b843-11606c196265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def preprocess_and_tokenize(train, val, test):\n",
    "    \"\"\"\n",
    "    Fonction pour découper les textes en mots, les tokeniser, créer un modèle Word2Vec,\n",
    "    et retourner le tokenizer, la taille du vocabulaire, les données tokenisées/padées, et les vecteurs Word2Vec.\n",
    "    \n",
    "    Args:\n",
    "        train (pandas DataFrame): DataFrame contenant les textes d'entraînement (colonne 'text').\n",
    "        val (pandas DataFrame): DataFrame contenant les textes de validation (colonne 'text').\n",
    "        test (pandas DataFrame): DataFrame contenant les textes de test (colonne 'text').\n",
    "\n",
    "    Returns:\n",
    "        tokenizer (Tokenizer): Le tokenizer entraîné sur les textes d'entraînement.\n",
    "        vocab_size (int): La taille du vocabulaire (nombre total de mots uniques + 1).\n",
    "        x_train (numpy array): Données d'entraînement tokenisées et padées.\n",
    "        x_val (numpy array): Données de validation tokenisées et padées.\n",
    "        x_test (numpy array): Données de test tokenisées et padées.\n",
    "        model_vectors (KeyedVectors): Vecteurs Word2Vec.\n",
    "        w2v_words (list): Liste des mots du vocabulaire Word2Vec.\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    # Découper les textes en mots\n",
    "    tweet_train_prep = [gensim.utils.simple_preprocess(text) for text in train]\n",
    "    tweet_val_prep = [gensim.utils.simple_preprocess(text) for text in val]\n",
    "    tweet_test_prep = [gensim.utils.simple_preprocess(text) for text in test]\n",
    "\n",
    "    # Création du modèle Word2Vec\n",
    "    w2v_model = gensim.models.Word2Vec(sentences=tweet_train_prep, vector_size=w2v_size, min_count=1, sg=1)\n",
    "    model_vectors = w2v_model.wv\n",
    "    w2v_words = model_vectors.index_to_key\n",
    "\n",
    "    # Initialisation du tokenizer\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(tweet_train_prep)\n",
    "    \n",
    "    # Tokenization et padding\n",
    "    x_train = pad_sequences(tokenizer.texts_to_sequences(tweet_train_prep), maxlen=max_sequence_len, padding='post')\n",
    "    x_val = pad_sequences(tokenizer.texts_to_sequences(tweet_val_prep), maxlen=max_sequence_len, padding='post')\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences(tweet_test_prep), maxlen=max_sequence_len, padding='post')\n",
    "    \n",
    "    # Taille du vocabulaire (+1 pour inclure le token 0 réservé au padding)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "    return tokenizer, vocab_size, x_train, x_val, x_test, model_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cf726d4-f975-4af7-8c72-29af21b04e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(tokenizer, model_vectors):\n",
    "    \"\"\"\n",
    "    Crée une matrice d'embeddings à partir du tokenizer et du modèle de vecteurs de mots.\n",
    "\n",
    "    Parameters:\n",
    "    tokenizer (Tokenizer): Un objet Tokenizer de Keras utilisé pour transformer les mots en indices.\n",
    "    model_vectors (KeyedVectors): Un modèle de vecteurs de mots de Gensim, où les clés sont les mots et les valeurs sont les vecteurs de mots.\n",
    "    w2v_size (int): La taille des vecteurs d'embeddings.\n",
    "\n",
    "    Returns:\n",
    "    tuple: La matrice d'embeddings (numpy array) et le taux de couverture des mots (float).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Index des mots dans le tokenizer\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index) + 1  # +1 pour le padding\n",
    "    embedding_matrix = np.zeros((vocab_size, w2v_size))\n",
    "\n",
    "    # Comptage du nombre de mots et de vecteurs trouvés\n",
    "    num_words_with_vectors = 0\n",
    "    total_words = len(word_index)\n",
    "    \n",
    "    for word, idx in word_index.items():\n",
    "        if word in model_vectors:\n",
    "            num_words_with_vectors += 1\n",
    "            embedding_vector = model_vectors[word]\n",
    "            if embedding_vector is not None and len(embedding_vector) == w2v_size:\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "\n",
    "    # Calcul du taux de couverture des mots\n",
    "    word_rate = np.round(num_words_with_vectors / total_words, 4)\n",
    "    \n",
    "    print(\"Embedding matrix shape: %s\" % str(embedding_matrix.shape))\n",
    "    print(\"Word coverage rate: %.4f\" % word_rate)\n",
    "    \n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2ab70c-5ffc-4aac-991b-ccd2c3b054e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_fct(embedding_matrix, vocab_size ) : \n",
    "    print(\"Build Keras model ...\")\n",
    "\n",
    "    dropout_level = 0.2\n",
    "\n",
    "    k_model = Sequential()\n",
    "    k_model.add(Embedding(vocab_size,\n",
    "                        w2v_size,\n",
    "                        weights=[embedding_matrix],\n",
    "                        input_length=max_sequence_len,\n",
    "                        trainable=True))\n",
    "\n",
    "    k_model.add(Bidirectional(LSTM(128, dropout=0.5, recurrent_dropout=0.2, return_sequences=True)))\n",
    "    k_model.add(GlobalAveragePooling1D())\n",
    "    k_model.add(Dense(32, activation='relu'))\n",
    "    k_model.add(Dropout(dropout_level))\n",
    "    k_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    k_model.compile(loss='categorical_crossentropy',\n",
    "                                optimizer='adam',\n",
    "    #                            metrics=[kmetrics.AUC()])\n",
    "                            metrics=['accuracy'])\n",
    "    k_model.build(input_shape=(None, 200))  # None pour le batch size variable\n",
    "\n",
    "    print(k_model.summary())\n",
    "\n",
    "    return k_model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae267364-838a-4e9f-95ff-f4097c32a38e",
   "metadata": {},
   "source": [
    "# MLFLOW - Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2693a5-192b-4077-aef0-c9fbd96c13ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/581637648930145205', creation_time=1730192161956, experiment_id='581637648930145205', last_update_time=1730192161956, lifecycle_stage='active', name='Model_avancee', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Ajouter l'URI du serveur de suivi MLflow\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5003')\n",
    "\n",
    "# Nom de l'expérience\n",
    "experiment_name = \"Model_avancee\"\n",
    "\n",
    "# Configurer MLflow pour utiliser l'expérience\n",
    "if mlflow.get_experiment_by_name(experiment_name) is None:\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c1403-9e79-4789-a25b-95ee83c8ed39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# W2V - Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe2e388-b8f7-4570-b20c-c6fd0224af46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2981, 200)\n",
      "Word coverage rate: 1.0000\n",
      "Build Keras model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">596,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">336,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │       \u001b[38;5;34m596,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m336,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">941,386</span> (3.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m941,386\u001b[0m (3.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">941,386</span> (3.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m941,386\u001b[0m (3.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.4938 - loss: 0.6932\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47813, saving model to path_data/models/Model_base_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 162ms/step - accuracy: 0.4926 - loss: 0.6933 - val_accuracy: 0.4781 - val_loss: 0.6935\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5112 - loss: 0.6915\n",
      "Epoch 2: val_accuracy improved from 0.47813 to 0.52188, saving model to path_data/models/Model_base_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.5113 - loss: 0.6915 - val_accuracy: 0.5219 - val_loss: 0.6911\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5448 - loss: 0.6892\n",
      "Epoch 3: val_accuracy improved from 0.52188 to 0.52812, saving model to path_data/models/Model_base_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.5440 - loss: 0.6894 - val_accuracy: 0.5281 - val_loss: 0.6895\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.5514 - loss: 0.6868\n",
      "Epoch 4: val_accuracy did not improve from 0.52812\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 180ms/step - accuracy: 0.5532 - loss: 0.6864 - val_accuracy: 0.5281 - val_loss: 0.6927\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.6895 - loss: 0.5995\n",
      "Epoch 5: val_accuracy improved from 0.52812 to 0.60000, saving model to path_data/models/Model_base_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 176ms/step - accuracy: 0.6981 - loss: 0.5920 - val_accuracy: 0.6000 - val_loss: 0.9693\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8864 - loss: 0.3254\n",
      "Epoch 6: val_accuracy improved from 0.60000 to 0.66250, saving model to path_data/models/Model_base_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.8884 - loss: 0.3222 - val_accuracy: 0.6625 - val_loss: 1.1098\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.9356 - loss: 0.2288\n",
      "Epoch 7: val_accuracy did not improve from 0.66250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9354 - loss: 0.2294 - val_accuracy: 0.6375 - val_loss: 1.1962\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9476 - loss: 0.2004\n",
      "Epoch 8: val_accuracy did not improve from 0.66250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.9485 - loss: 0.1974 - val_accuracy: 0.6125 - val_loss: 1.1275\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9457 - loss: 0.1904\n",
      "Epoch 9: val_accuracy did not improve from 0.66250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - accuracy: 0.9465 - loss: 0.1881 - val_accuracy: 0.6406 - val_loss: 1.2698\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9787 - loss: 0.1095\n",
      "Epoch 10: val_accuracy did not improve from 0.66250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.9785 - loss: 0.1096 - val_accuracy: 0.6344 - val_loss: 1.5554\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.9813 - loss: 0.0900\n",
      "Epoch 11: val_accuracy did not improve from 0.66250\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9813 - loss: 0.0900 - val_accuracy: 0.6313 - val_loss: 1.5243\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 17:12:34 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Entraîner et enregistrer le premier modèle\n",
    "def train_model_base_w2v():\n",
    "    train = df_train['text_base']\n",
    "    val = df_val['text_base']\n",
    "    test = df_test['text_base']\n",
    "\n",
    "    # Appliquer la fonction de prétraitement\n",
    "    tokenizer_1, vocab_size_1, x_train, x_val, x_test, model_vectors_1 = preprocess_and_tokenize(train, val, test)\n",
    "\n",
    "    # Calcul de la matrice d'embedding\n",
    "    embedding_matrix_1 = create_embedding_matrix(tokenizer_1, model_vectors_1)\n",
    "    embedding_matrix_1 = np.array(embedding_matrix_1)  # Conversion en tableau Numpy\n",
    "\n",
    "    # Démarrer un run pour le premier modèle avec MLflow\n",
    "    with mlflow.start_run(run_name=\"Model_Base_W2V\"):\n",
    "\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"vocab_size\", vocab_size_1)\n",
    "        mlflow.log_param(\"epochs\", 50)\n",
    "        mlflow.log_param(\"batch_size\", 128)\n",
    "        mlflow.log_param(\"early_stopping_patience\", 5)\n",
    "\n",
    "        # Création du modèle\n",
    "        model_1 = build_model_fct(embedding_matrix_1, vocab_size_1)\n",
    "\n",
    "        # Callbacks\n",
    "        model_save_path = 'path_data/models/Model_base_W2V.weights.h5'\n",
    "        save_model = ModelCheckpoint(filepath=model_save_path,\n",
    "                                     save_weights_only=True,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     mode='max',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
    "        callbacks = [save_model, early_stopping]\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history_1 = model_1.fit(x_train, y_train,\n",
    "                                epochs=50,\n",
    "                                verbose=True,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                batch_size=128,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Sauvegarder la configuration du modèle avec pickle\n",
    "        model_config_1 = model_1.get_config()\n",
    "        with open('path_data/models/Model_base_W2V_config.pkl', 'wb') as f:\n",
    "            pickle.dump(model_config_1, f)\n",
    "\n",
    "        # Charger les meilleurs poids du modèle\n",
    "        model_1.load_weights(model_save_path)\n",
    "\n",
    "        # Évaluer les performances sur les données de test\n",
    "        y_pred_proba_1 = model_1.predict(x_test)\n",
    "\n",
    "        # Calculer les prédictions binaires\n",
    "        y_pred_1 = (y_pred_proba_1 > 0.5).astype(int)\n",
    "\n",
    "        # Calculer les métriques de validation\n",
    "        auc_score_W2V_base = roc_auc_score(y_test, y_pred_proba_1, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        accuracy_W2V_base = accuracy_score(y_test, y_pred_1)\n",
    "        precision_W2V_base = precision_score(y_test, y_pred_1, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        recall_W2V_base = recall_score(y_test, y_pred_1, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        f1_W2V_base = f1_score(y_test, y_pred_1, average='macro')  # Changez 'macro' selon vos besoins\n",
    "\n",
    "        # Loguer les métriques dans MLflow\n",
    "        mlflow.log_metric(\"AUC\", auc_score_W2V_base)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_W2V_base)\n",
    "        mlflow.log_metric(\"Precision\", precision_W2V_base)\n",
    "        mlflow.log_metric(\"Recall\", recall_W2V_base)\n",
    "        mlflow.log_metric(\"F1 Score\", f1_W2V_base)\n",
    "\n",
    "        # Enregistrer le modèle avec MLflow\n",
    "        mlflow.keras.log_model(model_1, \"Model_Base_W2V\")\n",
    "\n",
    "# Exécuter la fonction pour entraîner le premier modèle\n",
    "train_model_base_w2v()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61d382-259e-4681-bc9a-9fa0bda44540",
   "metadata": {},
   "source": [
    "# W2V - Lemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b4ef23-3ba2-4f25-9b17-071c9838626c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2900, 200)\n",
      "Word coverage rate: 1.0000\n",
      "Build Keras model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">580,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">336,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │       \u001b[38;5;34m580,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m336,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">925,186</span> (3.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m925,186\u001b[0m (3.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">925,186</span> (3.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m925,186\u001b[0m (3.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4890 - loss: 0.6931\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52188, saving model to path_data/models/Model_lemma_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.4914 - loss: 0.6933 - val_accuracy: 0.5219 - val_loss: 0.6921\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5075 - loss: 0.6923\n",
      "Epoch 2: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.5054 - loss: 0.6925 - val_accuracy: 0.5219 - val_loss: 0.6919\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.5356 - loss: 0.6918\n",
      "Epoch 3: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.5360 - loss: 0.6918 - val_accuracy: 0.4781 - val_loss: 0.6926\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5690 - loss: 0.6890\n",
      "Epoch 4: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step - accuracy: 0.5690 - loss: 0.6888 - val_accuracy: 0.4781 - val_loss: 0.6924\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.6328 - loss: 0.6588\n",
      "Epoch 5: val_accuracy improved from 0.52188 to 0.66562, saving model to path_data/models/Model_lemma_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.6386 - loss: 0.6557 - val_accuracy: 0.6656 - val_loss: 0.6341\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.8736 - loss: 0.3765\n",
      "Epoch 6: val_accuracy did not improve from 0.66562\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.8750 - loss: 0.3736 - val_accuracy: 0.6562 - val_loss: 1.0660\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.9233 - loss: 0.2657\n",
      "Epoch 7: val_accuracy did not improve from 0.66562\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.9235 - loss: 0.2651 - val_accuracy: 0.6594 - val_loss: 0.9175\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9417 - loss: 0.2157\n",
      "Epoch 8: val_accuracy did not improve from 0.66562\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 0.9417 - loss: 0.2159 - val_accuracy: 0.6156 - val_loss: 1.0328\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.9596 - loss: 0.1442\n",
      "Epoch 9: val_accuracy did not improve from 0.66562\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 159ms/step - accuracy: 0.9600 - loss: 0.1433 - val_accuracy: 0.6156 - val_loss: 1.2685\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.9598 - loss: 0.1341\n",
      "Epoch 10: val_accuracy did not improve from 0.66562\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.9608 - loss: 0.1319 - val_accuracy: 0.6469 - val_loss: 1.5434\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 17:12:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Entraîner et enregistrer le deuxième modèle\n",
    "def train_model_lemma_w2v():\n",
    "    train = df_train['text_lemma']\n",
    "    val = df_val['text_lemma']\n",
    "    test = df_test['text_lemma']\n",
    "\n",
    "    # Appliquer la fonction de prétraitement\n",
    "    tokenizer_2, vocab_size_2, x_train, x_val, x_test, model_vectors_2 = preprocess_and_tokenize(train, val, test)\n",
    "\n",
    "    # Calcul de la matrice d'embedding\n",
    "    embedding_matrix_2 = create_embedding_matrix(tokenizer_2, model_vectors_2)\n",
    "    embedding_matrix_2 = np.array(embedding_matrix_2)  # Conversion en tableau Numpy\n",
    "\n",
    "    # Démarrer un run pour le deuxième modèle avec MLflow\n",
    "    with mlflow.start_run(run_name=\"Model_Lemma_W2V\"):\n",
    "\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"vocab_size\", vocab_size_2)\n",
    "        mlflow.log_param(\"epochs\", 50)\n",
    "        mlflow.log_param(\"batch_size\", 128)\n",
    "        mlflow.log_param(\"early_stopping_patience\", 5)\n",
    "\n",
    "        # Création du modèle\n",
    "        model_2 = build_model_fct(embedding_matrix_2, vocab_size_2)\n",
    "\n",
    "        # Callbacks\n",
    "        model_save_path = 'path_data/models/Model_lemma_W2V.weights.h5'\n",
    "        save_model = ModelCheckpoint(filepath=model_save_path,\n",
    "                                     save_weights_only=True,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     mode='max',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
    "        callbacks = [save_model, early_stopping]\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history_2 = model_2.fit(x_train, y_train,\n",
    "                                epochs=50,\n",
    "                                verbose=True,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                batch_size=128,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Sauvegarder la configuration du modèle avec pickle\n",
    "        model_config_2 = model_2.get_config()\n",
    "        with open('path_data/models/Model_lemma_W2V_config.pkl', 'wb') as f:\n",
    "            pickle.dump(model_config_2, f)\n",
    "\n",
    "        # Charger les meilleurs poids du modèle\n",
    "        model_2.load_weights(model_save_path)\n",
    "\n",
    "        # Évaluer les performances sur les données de test\n",
    "        y_pred_proba_2 = model_2.predict(x_test)\n",
    "\n",
    "        # Calculer les prédictions binaires\n",
    "        y_pred_2 = (y_pred_proba_2 > 0.5).astype(int)\n",
    "\n",
    "        # Calculer les métriques de validation\n",
    "        auc_score_W2V_lemma = roc_auc_score(y_test, y_pred_proba_2, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        accuracy_W2V_lemma = accuracy_score(y_test, y_pred_2)\n",
    "        precision_W2V_lemma = precision_score(y_test, y_pred_2, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        recall_W2V_lemma = recall_score(y_test, y_pred_2, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        f1_W2V_lemma = f1_score(y_test, y_pred_2, average='macro')  # Changez 'macro' selon vos besoins\n",
    "\n",
    "        # Loguer les métriques dans MLflow\n",
    "        mlflow.log_metric(\"AUC\", auc_score_W2V_lemma)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_W2V_lemma)\n",
    "        mlflow.log_metric(\"Precision\", precision_W2V_lemma)\n",
    "        mlflow.log_metric(\"Recall\", recall_W2V_lemma)\n",
    "        mlflow.log_metric(\"F1 Score\", f1_W2V_lemma)\n",
    "\n",
    "        # Enregistrer le modèle avec MLflow\n",
    "        mlflow.keras.log_model(model_2, \"Model_Lemma_W2V\")\n",
    "\n",
    "# Exécuter la fonction pour entraîner le deuxième modèle\n",
    "train_model_lemma_w2v()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b226cfd-e53d-44e5-8b56-1b984f1cb597",
   "metadata": {},
   "source": [
    "# W2v - Stemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f927219-f749-460c-b76d-dbdda8ecf793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2799, 200)\n",
      "Word coverage rate: 1.0000\n",
      "Build Keras model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">559,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">336,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │       \u001b[38;5;34m559,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m336,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">904,986</span> (3.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m904,986\u001b[0m (3.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">904,986</span> (3.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m904,986\u001b[0m (3.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4986 - loss: 0.6943\n",
      "Epoch 1: val_accuracy improved from -inf to 0.52188, saving model to path_data/models/Model_stemm_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.4963 - loss: 0.6942 - val_accuracy: 0.5219 - val_loss: 0.6925\n",
      "Epoch 2/50\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5084 - loss: 0.6932\n",
      "Epoch 2: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.5107 - loss: 0.6932 - val_accuracy: 0.5219 - val_loss: 0.6927\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.4924 - loss: 0.6926\n",
      "Epoch 3: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.4919 - loss: 0.6926 - val_accuracy: 0.5219 - val_loss: 0.6916\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5331 - loss: 0.6915\n",
      "Epoch 4: val_accuracy improved from 0.52188 to 0.61563, saving model to path_data/models/Model_stemm_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.5322 - loss: 0.6915 - val_accuracy: 0.6156 - val_loss: 0.6920\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.5600 - loss: 0.6904\n",
      "Epoch 5: val_accuracy did not improve from 0.61563\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 163ms/step - accuracy: 0.5605 - loss: 0.6903 - val_accuracy: 0.5938 - val_loss: 0.6888\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.5966 - loss: 0.6797\n",
      "Epoch 6: val_accuracy did not improve from 0.61563\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.5973 - loss: 0.6789 - val_accuracy: 0.5938 - val_loss: 0.6624\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8008 - loss: 0.5195\n",
      "Epoch 7: val_accuracy improved from 0.61563 to 0.67188, saving model to path_data/models/Model_stemm_W2V.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 193ms/step - accuracy: 0.8028 - loss: 0.5149 - val_accuracy: 0.6719 - val_loss: 0.9042\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.8956 - loss: 0.3449\n",
      "Epoch 8: val_accuracy did not improve from 0.67188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.8973 - loss: 0.3408 - val_accuracy: 0.6438 - val_loss: 0.9149\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9561 - loss: 0.1875\n",
      "Epoch 9: val_accuracy did not improve from 0.67188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.9541 - loss: 0.1915 - val_accuracy: 0.6281 - val_loss: 1.0248\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9386 - loss: 0.2120\n",
      "Epoch 10: val_accuracy did not improve from 0.67188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.9393 - loss: 0.2122 - val_accuracy: 0.6313 - val_loss: 1.2436\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.9358 - loss: 0.2365\n",
      "Epoch 11: val_accuracy did not improve from 0.67188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.9367 - loss: 0.2336 - val_accuracy: 0.6406 - val_loss: 1.2973\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9686 - loss: 0.1636\n",
      "Epoch 12: val_accuracy did not improve from 0.67188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.9684 - loss: 0.1637 - val_accuracy: 0.6219 - val_loss: 1.2958\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 17:13:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Entraîner et enregistrer le troisième modèle\n",
    "def train_model_stemm_w2v():\n",
    "    train = df_train['text_stem']\n",
    "    val = df_val['text_stem']\n",
    "    test = df_test['text_stem']\n",
    "\n",
    "    # Appliquer la fonction de prétraitement\n",
    "    tokenizer_3, vocab_size_3, x_train, x_val, x_test, model_vectors_3 = preprocess_and_tokenize(train, val, test)\n",
    "\n",
    "    # Calcul de la matrice d'embedding\n",
    "    embedding_matrix_3 = create_embedding_matrix(tokenizer_3, model_vectors_3)\n",
    "    embedding_matrix_3 = np.array(embedding_matrix_3)  # Conversion en tableau Numpy\n",
    "\n",
    "    # Démarrer un run pour le troisième modèle avec MLflow\n",
    "    with mlflow.start_run(run_name=\"Model_Stemm_W2V\"):\n",
    "\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"vocab_size\", vocab_size_3)\n",
    "        mlflow.log_param(\"epochs\", 50)\n",
    "        mlflow.log_param(\"batch_size\", 128)\n",
    "        mlflow.log_param(\"early_stopping_patience\", 5)\n",
    "\n",
    "        # Création du modèle\n",
    "        model_3 = build_model_fct(embedding_matrix_3, vocab_size_3)\n",
    "\n",
    "        # Callbacks\n",
    "        model_save_path = 'path_data/models/Model_stemm_W2V.weights.h5'\n",
    "        save_model = ModelCheckpoint(filepath=model_save_path,\n",
    "                                     save_weights_only=True,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     mode='max',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
    "        callbacks = [save_model, early_stopping]\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history_3 = model_3.fit(x_train, y_train,\n",
    "                                epochs=50,\n",
    "                                verbose=True,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                batch_size=128,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Sauvegarder la configuration du modèle avec pickle\n",
    "        model_config_3 = model_3.get_config()\n",
    "        with open('path_data/models/Model_stemm_W2V_config.pkl', 'wb') as f:\n",
    "            pickle.dump(model_config_3, f)\n",
    "\n",
    "        # Charger les meilleurs poids du modèle\n",
    "        model_3.load_weights(model_save_path)\n",
    "\n",
    "        # Évaluer les performances sur les données de test\n",
    "        y_pred_proba_3 = model_3.predict(x_test)\n",
    "\n",
    "        # Calculer les prédictions binaires\n",
    "        y_pred_3 = (y_pred_proba_3 > 0.5).astype(int)\n",
    "\n",
    "        # Calculer les métriques de validation\n",
    "        auc_score_W2V_stemm = roc_auc_score(y_test, y_pred_proba_3, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        accuracy_W2V_stemm = accuracy_score(y_test, y_pred_3)\n",
    "        precision_W2V_stemm = precision_score(y_test, y_pred_3, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        recall_W2V_stemm = recall_score(y_test, y_pred_3, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        f1_W2V_stemm = f1_score(y_test, y_pred_3, average='macro')  # Changez 'macro' selon vos besoins\n",
    "\n",
    "        # Loguer les métriques dans MLflow\n",
    "        mlflow.log_metric(\"AUC\", auc_score_W2V_stemm)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_W2V_stemm)\n",
    "        mlflow.log_metric(\"Precision\", precision_W2V_stemm)\n",
    "        mlflow.log_metric(\"Recall\", recall_W2V_stemm)\n",
    "        mlflow.log_metric(\"F1 Score\", f1_W2V_stemm)\n",
    "\n",
    "        # Enregistrer le modèle avec MLflow\n",
    "        mlflow.keras.log_model(model_3, \"Model_Stemm_W2V\")\n",
    "\n",
    "# Exécuter la fonction pour entraîner le troisième modèle\n",
    "train_model_stemm_w2v()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24f999-f59e-4a77-a1d3-2568a2fa29ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Glove - Fonction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34398fde-ab0b-4044-850a-9aa38bd8bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target']\n",
    "y_val = df_val['target']\n",
    "y_test = df_test['target']\n",
    "\n",
    "\n",
    "num_words=40000\n",
    "maxlen=200\n",
    "embedding_dim = 200\n",
    "filepath = '/Users/chretien/Desktop/OC7/glove.twitter.27B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e7a9362-2b08-432e-97a7-e2cfd60602ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_texts(train, val, test):\n",
    "    \"\"\"\n",
    "    Prétraite les textes en les transformant en vecteurs de séquences et en les padant.\n",
    "\n",
    "    Args:\n",
    "        train_df (pandas DataFrame): DataFrame contenant les textes d'entraînement (colonne 'text').\n",
    "        val_df (pandas DataFrame): DataFrame contenant les textes de validation (colonne 'text').\n",
    "        test_df (pandas DataFrame): DataFrame contenant les textes de test (colonne 'text').\n",
    "        num_words (int): Nombre maximum de mots à utiliser dans le Tokenizer.\n",
    "        maxlen (int): Longueur maximale des séquences après padding.\n",
    "\n",
    "    Returns:\n",
    "        tokenizer (Tokenizer): Le tokenizer entraîné sur les textes d'entraînement.\n",
    "        vocab_size (int): La taille du vocabulaire (nombre total de mots uniques + 1).\n",
    "        X_train (numpy array): Données d'entraînement tokenisées et padées.\n",
    "        X_val (numpy array): Données de validation tokenisées et padées.\n",
    "        X_test (numpy array): Données de test tokenisées et padées.\n",
    "    \"\"\"\n",
    "    # Initialiser le Tokenizer\n",
    "    tokenizer = Tokenizer(num_words=num_words)\n",
    "    \n",
    "    # Entraîner le Tokenizer sur les textes d'entraînement\n",
    "    tokenizer.fit_on_texts(train)\n",
    "    \n",
    "    # Convertir les textes en séquences d'entiers (tokenization)\n",
    "    X_train = tokenizer.texts_to_sequences(train)\n",
    "    X_val = tokenizer.texts_to_sequences(val)\n",
    "    X_test = tokenizer.texts_to_sequences(test)\n",
    "    \n",
    "    # Ajouter 1 pour inclure le token 0 réservé au padding\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    print(\"Vocabulary size:\", vocab_size)\n",
    "    \n",
    "    # Padding des séquences pour avoir une longueur fixe\n",
    "    X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "    X_val = pad_sequences(X_val, padding='post', maxlen=maxlen)\n",
    "    X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "    \n",
    "    return tokenizer, vocab_size, X_train, X_val, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d584660-ca48-4874-bd12-bac418a3fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(filepath,vocab_size, word_index):\n",
    "    \"\"\"\n",
    "    Crée une matrice d'embeddings pour les mots en utilisant un fichier de vecteurs de mots.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Chemin vers le fichier contenant les vecteurs de mots (format texte).\n",
    "        word_index (dict): Dictionnaire où les clés sont les mots et les valeurs sont les indices de ces mots dans le tokenizer.\n",
    "        embedding_dim (int): La taille des vecteurs d'embeddings.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: La matrice d'embeddings, où chaque ligne correspond à un vecteur de mot.\n",
    "    \"\"\"\n",
    "    vocab_size = len(word_index) + 1  # Ajouter 1 pour inclure l'index 0 réservé au padding\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))  # Initialiser la matrice avec des zéros\n",
    "\n",
    "    # Comptage pour le taux de couverture des mots\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    # Lire le fichier de vecteurs de mots\n",
    "    with open(filepath, encoding='utf8', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                j += 1\n",
    "                idx = word_index[word]\n",
    "                # Assigner le vecteur au mot correspondant\n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "    \n",
    "    # Calculer le taux de couverture des mots\n",
    "    word_rate = np.round((j / i) * 100, 4)\n",
    "    print(\"Total number of lines read:\", i)\n",
    "    print(\"Number of words found in the word_index:\", j)\n",
    "    print(\"Word embedding rate: {}%\".format(word_rate))\n",
    "    \n",
    "    return embedding_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8e59c87-f6df-4629-9b80-eea07d28421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Dropout\n",
    "\n",
    "def create_model(vocab_size, embedding_matrix):\n",
    "    \"\"\"\n",
    "    Crée et compile un modèle Keras pour la classification binaire du texte.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): La taille du vocabulaire (nombre total de mots uniques + 1).\n",
    "        embedding_dim (int): La taille des vecteurs d'embeddings.\n",
    "        embedding_matrix (numpy array): La matrice d'embeddings à utiliser pour la couche d'embeddings.\n",
    "        maxlen (int): Longueur maximale des séquences après padding.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): Le modèle Keras construit et compilé.\n",
    "    \"\"\"\n",
    "    print(\"Building Keras model...\")\n",
    "\n",
    "    # Initialisation du modèle séquentiel\n",
    "    model = Sequential()\n",
    "\n",
    "    # Couche d'Embedding\n",
    "    model.add(layers.Embedding(input_dim=vocab_size,\n",
    "                               output_dim=embedding_dim,\n",
    "                               weights=[embedding_matrix],\n",
    "                               input_length=maxlen,\n",
    "                               trainable=True))\n",
    "\n",
    "    # Couche LSTM bidirectionnelle\n",
    "    model.add(Bidirectional(LSTM(128, dropout=0.5, recurrent_dropout=0.2, return_sequences=True)))\n",
    "    \n",
    "    # Couche de pooling global\n",
    "    model.add(GlobalAveragePooling1D())\n",
    "    \n",
    "    # Couche Dense\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    \n",
    "    # Couche Dropout\n",
    "    model.add(Dropout(0.75))\n",
    "    \n",
    "    # Couche de sortie avec activation sigmoïde\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compilation du modèle\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Construction du modèle avec une forme d'entrée variable pour le batch size\n",
    "    model.build(input_shape=(None, maxlen))  # None pour le batch size variable\n",
    "\n",
    "    # Affichage du résumé du modèle\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484524b-d53a-4fc3-aad6-c18c71e30b16",
   "metadata": {},
   "source": [
    "# Glove - Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b9c2408-3456-4cca-a5b6-6488de144b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3121\n",
      "Total number of lines read: 1193514\n",
      "Number of words found in the word_index: 2784\n",
      "Word embedding rate: 0.2333%\n",
      "Building Keras model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">624,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">336,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │       \u001b[38;5;34m624,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m336,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">969,353</span> (3.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m969,353\u001b[0m (3.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">969,353</span> (3.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m969,353\u001b[0m (3.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step - accuracy: 0.5076 - loss: 0.6977\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54062, saving model to path_data/models/Model_base_Glove.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 588ms/step - accuracy: 0.5056 - loss: 0.6980 - val_accuracy: 0.5406 - val_loss: 0.6929\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - accuracy: 0.4909 - loss: 0.6965\n",
      "Epoch 2: val_accuracy did not improve from 0.54062\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 777ms/step - accuracy: 0.4901 - loss: 0.6965 - val_accuracy: 0.5219 - val_loss: 0.6918\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685ms/step - accuracy: 0.4992 - loss: 0.6971\n",
      "Epoch 3: val_accuracy did not improve from 0.54062\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.5001 - loss: 0.6970 - val_accuracy: 0.5219 - val_loss: 0.6921\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.5169 - loss: 0.6932\n",
      "Epoch 4: val_accuracy did not improve from 0.54062\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 840ms/step - accuracy: 0.5154 - loss: 0.6933 - val_accuracy: 0.4781 - val_loss: 0.6940\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721ms/step - accuracy: 0.4819 - loss: 0.7005\n",
      "Epoch 5: val_accuracy did not improve from 0.54062\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 842ms/step - accuracy: 0.4831 - loss: 0.7002 - val_accuracy: 0.5219 - val_loss: 0.6927\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834ms/step - accuracy: 0.4837 - loss: 0.6950\n",
      "Epoch 6: val_accuracy did not improve from 0.54062\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 966ms/step - accuracy: 0.4861 - loss: 0.6949 - val_accuracy: 0.5219 - val_loss: 0.6927\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 136ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 17:14:19 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Entraîner et enregistrer le quatrième modèle\n",
    "def train_model_base_glove():\n",
    "    train = df_train['text_base']\n",
    "    val = df_val['text_base']\n",
    "    test = df_test['text_base']\n",
    "\n",
    "    # Prétraiter les données\n",
    "    tokenizer_4, vocab_size_4, X_train, X_val, X_test = preprocess_texts(train, val, test)\n",
    "\n",
    "    # Créer la matrice d'embedding\n",
    "    embedding_matrix_4 = create_embedding_matrix(filepath, vocab_size_4, tokenizer_4.word_index)\n",
    "\n",
    "    # Démarrer un run pour le quatrième modèle avec MLflow\n",
    "    with mlflow.start_run(run_name=\"Model_Base_Glove\"):\n",
    "\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"vocab_size\", vocab_size_4)\n",
    "        mlflow.log_param(\"epochs\", 50)\n",
    "        mlflow.log_param(\"batch_size\", 128)\n",
    "        mlflow.log_param(\"early_stopping_patience\", 5)\n",
    "\n",
    "        # Création du modèle\n",
    "        model_4 = create_model(vocab_size_4, embedding_matrix_4)\n",
    "\n",
    "        # Callbacks\n",
    "        model_save_path = 'path_data/models/Model_base_Glove.weights.h5'\n",
    "        save_model = ModelCheckpoint(filepath=model_save_path,\n",
    "                                     save_weights_only=True,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     mode='max',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
    "        callbacks = [save_model, early_stopping]\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history_4 = model_4.fit(X_train, y_train,\n",
    "                                epochs=50,\n",
    "                                verbose=True,\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                batch_size=128,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Sauvegarder la configuration du modèle avec pickle\n",
    "        model_config_4 = model_4.get_config()\n",
    "        with open('path_data/models/Model_base_Glove_config.pkl', 'wb') as f:\n",
    "            pickle.dump(model_config_4, f)\n",
    "\n",
    "        # Charger les meilleurs poids du modèle\n",
    "        model_4.load_weights(model_save_path)\n",
    "\n",
    "        # Évaluer les performances sur les données de test\n",
    "        y_pred_proba_4 = model_4.predict(X_test)\n",
    "\n",
    "        # Calculer les prédictions binaires\n",
    "        y_pred_4 = (y_pred_proba_4 > 0.5).astype(int)\n",
    "\n",
    "        # Calculer les métriques de validation\n",
    "        auc_score_Glove_base = roc_auc_score(y_test, y_pred_proba_4, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        accuracy_Glove_base = accuracy_score(y_test, y_pred_4)\n",
    "        precision_Glove_base = precision_score(y_test, y_pred_4, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        recall_Glove_base = recall_score(y_test, y_pred_4, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        f1_Glove_base = f1_score(y_test, y_pred_4, average='macro')  # Changez 'macro' selon vos besoins\n",
    "\n",
    "        # Loguer les métriques dans MLflow\n",
    "        mlflow.log_metric(\"AUC\", auc_score_Glove_base)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_Glove_base)\n",
    "        mlflow.log_metric(\"Precision\", precision_Glove_base)\n",
    "        mlflow.log_metric(\"Recall\", recall_Glove_base)\n",
    "        mlflow.log_metric(\"F1 Score\", f1_Glove_base)\n",
    "\n",
    "        # Enregistrer le modèle avec MLflow\n",
    "        mlflow.keras.log_model(model_4, \"Model_Base_Glove\")\n",
    "\n",
    "# Exécuter la fonction pour entraîner le quatrième modèle\n",
    "train_model_base_glove()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ec183-1d2c-4271-874a-2b72a179218f",
   "metadata": {},
   "source": [
    "# Glove - lemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb5c19d4-40f5-40e0-a82a-3a6a4c6c8508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 3038\n",
      "Total number of lines read: 1193514\n",
      "Number of words found in the word_index: 2704\n",
      "Word embedding rate: 0.2266%\n",
      "Building Keras model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">607,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">336,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │       \u001b[38;5;34m607,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m336,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">952,753</span> (3.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m952,753\u001b[0m (3.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">952,753</span> (3.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m952,753\u001b[0m (3.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.4771 - loss: 0.6948\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47813, saving model to path_data/models/Model_lemma_Glove.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 479ms/step - accuracy: 0.4772 - loss: 0.6949 - val_accuracy: 0.4781 - val_loss: 0.6945\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667ms/step - accuracy: 0.5142 - loss: 0.6949\n",
      "Epoch 2: val_accuracy did not improve from 0.47813\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 779ms/step - accuracy: 0.5133 - loss: 0.6950 - val_accuracy: 0.4781 - val_loss: 0.6933\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - accuracy: 0.4736 - loss: 0.6948\n",
      "Epoch 3: val_accuracy improved from 0.47813 to 0.52188, saving model to path_data/models/Model_lemma_Glove.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 858ms/step - accuracy: 0.4744 - loss: 0.6947 - val_accuracy: 0.5219 - val_loss: 0.6919\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.4980 - loss: 0.6995\n",
      "Epoch 4: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 787ms/step - accuracy: 0.4983 - loss: 0.6994 - val_accuracy: 0.5219 - val_loss: 0.6928\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655ms/step - accuracy: 0.4963 - loss: 0.6941\n",
      "Epoch 5: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 749ms/step - accuracy: 0.4959 - loss: 0.6940 - val_accuracy: 0.5219 - val_loss: 0.6927\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.4919 - loss: 0.6964\n",
      "Epoch 6: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 729ms/step - accuracy: 0.4914 - loss: 0.6963 - val_accuracy: 0.5219 - val_loss: 0.6924\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710ms/step - accuracy: 0.4905 - loss: 0.6950\n",
      "Epoch 7: val_accuracy improved from 0.52188 to 0.52812, saving model to path_data/models/Model_lemma_Glove.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.4908 - loss: 0.6950 - val_accuracy: 0.5281 - val_loss: 0.6929\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - accuracy: 0.4714 - loss: 0.6961\n",
      "Epoch 8: val_accuracy did not improve from 0.52812\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 752ms/step - accuracy: 0.4715 - loss: 0.6961 - val_accuracy: 0.4781 - val_loss: 0.6932\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712ms/step - accuracy: 0.4947 - loss: 0.6927\n",
      "Epoch 9: val_accuracy did not improve from 0.52812\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 835ms/step - accuracy: 0.4952 - loss: 0.6928 - val_accuracy: 0.4781 - val_loss: 0.6943\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.4944 - loss: 0.6960\n",
      "Epoch 10: val_accuracy did not improve from 0.52812\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 719ms/step - accuracy: 0.4927 - loss: 0.6960 - val_accuracy: 0.5219 - val_loss: 0.6928\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - accuracy: 0.5074 - loss: 0.6925\n",
      "Epoch 11: val_accuracy did not improve from 0.52812\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 703ms/step - accuracy: 0.5065 - loss: 0.6925 - val_accuracy: 0.5219 - val_loss: 0.6927\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719ms/step - accuracy: 0.4994 - loss: 0.6932\n",
      "Epoch 12: val_accuracy did not improve from 0.52812\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.4995 - loss: 0.6932 - val_accuracy: 0.5219 - val_loss: 0.6931\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/29 17:15:54 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Entraîner et enregistrer le cinquième modèle\n",
    "def train_model_lemma_glove():\n",
    "    train = df_train['text_lemma']\n",
    "    val = df_val['text_lemma']\n",
    "    test = df_test['text_lemma']\n",
    "\n",
    "    # Prétraiter les données\n",
    "    tokenizer_5, vocab_size_5, X_train, X_val, X_test = preprocess_texts(train, val, test)\n",
    "\n",
    "    # Créer la matrice d'embedding\n",
    "    embedding_matrix_5 = create_embedding_matrix(filepath, vocab_size_5, tokenizer_5.word_index)\n",
    "\n",
    "    # Démarrer un run pour le cinquième modèle avec MLflow\n",
    "    with mlflow.start_run(run_name=\"Model_Lemma_Glove\"):\n",
    "\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"vocab_size\", vocab_size_5)\n",
    "        mlflow.log_param(\"epochs\", 50)\n",
    "        mlflow.log_param(\"batch_size\", 128)\n",
    "        mlflow.log_param(\"early_stopping_patience\", 5)\n",
    "\n",
    "        # Création du modèle\n",
    "        model_5 = create_model(vocab_size_5, embedding_matrix_5)\n",
    "\n",
    "        # Callbacks\n",
    "        model_save_path = 'path_data/models/Model_lemma_Glove.weights.h5'\n",
    "        save_model = ModelCheckpoint(filepath=model_save_path,\n",
    "                                     save_weights_only=True,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     mode='max',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
    "        callbacks = [save_model, early_stopping]\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history_5 = model_5.fit(X_train, y_train,\n",
    "                                epochs=50,\n",
    "                                verbose=True,\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                batch_size=128,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Sauvegarder la configuration du modèle avec pickle\n",
    "        model_config_5 = model_5.get_config()\n",
    "        with open('path_data/models/Model_lemma_Glove_config.pkl', 'wb') as f:\n",
    "            pickle.dump(model_config_5, f)\n",
    "\n",
    "        # Charger les meilleurs poids du modèle\n",
    "        model_5.load_weights(model_save_path)\n",
    "\n",
    "        # Évaluer les performances sur les données de test\n",
    "        y_pred_proba_5 = model_5.predict(X_test)\n",
    "\n",
    "        # Calculer les prédictions binaires\n",
    "        y_pred_5 = (y_pred_proba_5 > 0.5).astype(int)\n",
    "\n",
    "        # Calculer les métriques de validation\n",
    "        auc_score_Glove_lemma = roc_auc_score(y_test, y_pred_proba_5, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        accuracy_Glove_lemma = accuracy_score(y_test, y_pred_5)\n",
    "        precision_Glove_lemma = precision_score(y_test, y_pred_5, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        recall_Glove_lemma = recall_score(y_test, y_pred_5, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        f1_Glove_lemma = f1_score(y_test, y_pred_5, average='macro')  # Changez 'macro' selon vos besoins\n",
    "\n",
    "        # Loguer les métriques dans MLflow\n",
    "        mlflow.log_metric(\"AUC\", auc_score_Glove_lemma)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_Glove_lemma)\n",
    "        mlflow.log_metric(\"Precision\", precision_Glove_lemma)\n",
    "        mlflow.log_metric(\"Recall\", recall_Glove_lemma)\n",
    "        mlflow.log_metric(\"F1 Score\", f1_Glove_lemma)\n",
    "\n",
    "        # Enregistrer le modèle avec MLflow\n",
    "        mlflow.keras.log_model(model_5, \"Model_Lemma_Glove\")\n",
    "\n",
    "# Exécuter la fonction pour entraîner le cinquième modèle\n",
    "train_model_lemma_glove()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5509b8-8a64-479b-9e71-5c11ab71e68e",
   "metadata": {},
   "source": [
    "# Glove - stemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be2cd867-b703-4f74-9f33-e204e0800f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 2941\n",
      "Total number of lines read: 1193514\n",
      "Number of words found in the word_index: 2504\n",
      "Word embedding rate: 0.2098%\n",
      "Building Keras model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">588,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">336,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │       \u001b[38;5;34m588,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │       \u001b[38;5;34m336,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">933,353</span> (3.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m933,353\u001b[0m (3.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">933,353</span> (3.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m933,353\u001b[0m (3.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524ms/step - accuracy: 0.5284 - loss: 0.6973\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47813, saving model to path_data/models/Model_stemm_Glove.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 626ms/step - accuracy: 0.5262 - loss: 0.6977 - val_accuracy: 0.4781 - val_loss: 0.6954\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - accuracy: 0.4977 - loss: 0.6959\n",
      "Epoch 2: val_accuracy improved from 0.47813 to 0.52188, saving model to path_data/models/Model_stemm_Glove.weights.h5\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 780ms/step - accuracy: 0.4971 - loss: 0.6962 - val_accuracy: 0.5219 - val_loss: 0.6918\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605ms/step - accuracy: 0.5046 - loss: 0.6929\n",
      "Epoch 3: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 702ms/step - accuracy: 0.5062 - loss: 0.6928 - val_accuracy: 0.4781 - val_loss: 0.6960\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649ms/step - accuracy: 0.5270 - loss: 0.6988\n",
      "Epoch 4: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 758ms/step - accuracy: 0.5271 - loss: 0.6987 - val_accuracy: 0.5219 - val_loss: 0.6917\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654ms/step - accuracy: 0.4726 - loss: 0.6956\n",
      "Epoch 5: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 751ms/step - accuracy: 0.4743 - loss: 0.6956 - val_accuracy: 0.5219 - val_loss: 0.6918\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627ms/step - accuracy: 0.4929 - loss: 0.6937\n",
      "Epoch 6: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 736ms/step - accuracy: 0.4944 - loss: 0.6937 - val_accuracy: 0.5219 - val_loss: 0.6910\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - accuracy: 0.5025 - loss: 0.6955\n",
      "Epoch 7: val_accuracy did not improve from 0.52188\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 840ms/step - accuracy: 0.5014 - loss: 0.6956 - val_accuracy: 0.5094 - val_loss: 0.6928\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/10/29 17:17:00 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "# Entraîner et enregistrer le sixième modèle\n",
    "def train_model_stemm_glove():\n",
    "    train = df_train['text_stem']\n",
    "    val = df_val['text_stem']\n",
    "    test = df_test['text_stem']\n",
    "\n",
    "    # Prétraiter les données\n",
    "    tokenizer_6, vocab_size_6, X_train, X_val, X_test = preprocess_texts(train, val, test)\n",
    "\n",
    "    # Créer la matrice d'embedding\n",
    "    embedding_matrix_6 = create_embedding_matrix(filepath, vocab_size_6, tokenizer_6.word_index)\n",
    "\n",
    "    # Démarrer un run pour le sixième modèle avec MLflow\n",
    "    with mlflow.start_run(run_name=\"Model_Stemm_Glove\"):\n",
    "\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"vocab_size\", vocab_size_6)\n",
    "        mlflow.log_param(\"epochs\", 50)\n",
    "        mlflow.log_param(\"batch_size\", 128)\n",
    "        mlflow.log_param(\"early_stopping_patience\", 5)\n",
    "\n",
    "        # Création du modèle\n",
    "        model_6 = create_model(vocab_size_6, embedding_matrix_6)\n",
    "\n",
    "        # Callbacks\n",
    "        model_save_path = 'path_data/models/Model_stemm_Glove.weights.h5'\n",
    "        save_model = ModelCheckpoint(filepath=model_save_path,\n",
    "                                     save_weights_only=True,\n",
    "                                     monitor='val_accuracy',\n",
    "                                     mode='max',\n",
    "                                     save_best_only=True,\n",
    "                                     verbose=1)\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, verbose=0, mode='max')\n",
    "        callbacks = [save_model, early_stopping]\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        history_6 = model_6.fit(X_train, y_train,\n",
    "                                epochs=50,\n",
    "                                verbose=True,\n",
    "                                validation_data=(X_val, y_val),\n",
    "                                batch_size=128,\n",
    "                                callbacks=callbacks)\n",
    "\n",
    "        # Sauvegarder la configuration du modèle avec pickle\n",
    "        model_config_6 = model_6.get_config()\n",
    "        with open('path_data/models/Model_stemm_Glove_config.pkl', 'wb') as f:\n",
    "            pickle.dump(model_config_6, f)\n",
    "\n",
    "        # Charger les meilleurs poids du modèle\n",
    "        model_6.load_weights(model_save_path)\n",
    "\n",
    "        # Évaluer les performances sur les données de test\n",
    "        y_pred_proba_6 = model_6.predict(X_test)\n",
    "\n",
    "        # Calculer les prédictions binaires\n",
    "        y_pred_6 = (y_pred_proba_6 > 0.5).astype(int)\n",
    "\n",
    "        # Calculer les métriques de validation\n",
    "        auc_score_Glove_stemm = roc_auc_score(y_test, y_pred_proba_6, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        accuracy_Glove_stemm = accuracy_score(y_test, y_pred_6)\n",
    "        precision_Glove_stemm = precision_score(y_test, y_pred_6, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        recall_Glove_stemm = recall_score(y_test, y_pred_6, average='macro')  # Changez 'macro' selon vos besoins\n",
    "        f1_Glove_stemm = f1_score(y_test, y_pred_6, average='macro')  # Changez 'macro' selon vos besoins\n",
    "\n",
    "        # Loguer les métriques dans MLflow\n",
    "        mlflow.log_metric(\"AUC\", auc_score_Glove_stemm)\n",
    "        mlflow.log_metric(\"Accuracy\", accuracy_Glove_stemm)\n",
    "        mlflow.log_metric(\"Precision\", precision_Glove_stemm)\n",
    "        mlflow.log_metric(\"Recall\", recall_Glove_stemm)\n",
    "        mlflow.log_metric(\"F1 Score\", f1_Glove_stemm)\n",
    "\n",
    "        # Enregistrer le modèle avec MLflow\n",
    "        mlflow.keras.log_model(model_6, \"Model_Stemm_Glove\")\n",
    "\n",
    "# Exécuter la fonction pour entraîner le sixième modèle\n",
    "train_model_stemm_glove()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a9733-3560-4768-8859-795188cf529e",
   "metadata": {},
   "source": [
    "# test mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52cdfe-5727-4951-953a-b8cf4870eece",
   "metadata": {},
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ab2df-516f-4613-94ba-2f405b6b4e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5806bdf2-21af-44af-ada7-2b87ba274f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "224b6aa2-18bb-46fa-8938-a1f4ca8daa6b",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Création du dictionnaire des résultats avec les corrections\n",
    "results = {\n",
    "    'Modèle': [ 'W2V_base', 'W2V_lemma', 'W2V_stemm', 'Glove_base', 'Glove_lemma', 'Glove_stemm'],\n",
    "    'AUC': [auc_score_W2V_base, auc_score_W2V_lemma, auc_score_W2V_stemm, auc_score_Glove_base, auc_score_Glove_lemma, auc_score_Glove_stemm],\n",
    "    'Accuracy_score': [accuracy_W2V_base, accuracy_W2V_lemma, accuracy_W2V_stemm, accuracy_Glove_base, accuracy_Glove_lemma, accuracy_Glove_stemm]\n",
    "}\n",
    "\n",
    "# Création du DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Tri du DataFrame par AUC (du meilleur au moins bon)\n",
    "df_sorted_auc = df_results.sort_values(by='AUC', ascending=False)\n",
    "\n",
    "# Affichage du DataFrame trié par AUC\n",
    "df_sorted_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0ad6b-824f-4da4-a306-628d15bd09d5",
   "metadata": {},
   "source": [
    "# Sauvegarder mes transformers et model pour le best model "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4ddddb1-7cb2-441c-8887-ccd63556ee00",
   "metadata": {},
   "source": [
    "import h5py\n",
    "\n",
    "# Sauvegarder la configuration du modèle avec pickle\n",
    "model_config_2 = model_2.get_config()  # Obtient la configuration du modèle\n",
    "with open('API/Model_lemma_W2V_config.pkl', 'wb') as f:\n",
    "    pickle.dump(model_config_2, f )\n",
    "\n",
    "# Sauvegarder la configuration du modèle en format JSON\n",
    "model_config_json = model_2.to_json()\n",
    "with open('API/Model_lemma_W2V_config.json', 'w') as f:\n",
    "    f.write(model_config_json)\n",
    "\n",
    "\n",
    "# Sauvegarder les poids du modèle\n",
    "weights_path = 'API/Model_lemma_W2V.weights.h5'\n",
    "model_2.save_weights(weights_path)\n",
    "\n",
    "# Charger les poids dans un tableau numpy\n",
    "weights = {}\n",
    "with h5py.File(weights_path, 'r') as f:\n",
    "    for layer in f.keys():\n",
    "        weights[layer] = np.array(f[layer])\n",
    "\n",
    "# Sauvegarder les poids avec pickle\n",
    "with open('API/Model_lemma_W2V_weights.pkl', 'wb') as f:\n",
    "    pickle.dump(weights, f)\n",
    "\n",
    "\n",
    "\n",
    "# Chemin vers le fichier de sauvegarde\n",
    "pickle_file_path = 'API/embedding_and_tokenizer.pkl'\n",
    "\n",
    "# Enregistrer les objets\n",
    "with open(pickle_file_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'embedding_matrix': embedding_matrix_2,\n",
    "        'tokenizer': tokenizer_2,\n",
    "        'model_vectors': model_vectors_2\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47d684-c776-40b3-9984-11be7392e3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad13326-9576-42a9-9cff-0b7317aeeb80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
